% function results = trainStandardAgent(agent, env, agent_name, max_episodes,base_path)
%     % Determine if agent is off-policy
%     mkdir([base_path,'/','agents',agent_name])
%     offPolicyAgents = ["rlDDPGAgent","rlTD3Agent","rlSACAgent"];
%     isOffPolicy = any(strcmp(class(agent), offPolicyAgents));
%     if isOffPolicy || strcmp(agent_name,'A3C')
%         disp('OffPolicy, async parrallelization')
%         trainOpts = rlTrainingOptions(...
%         MaxEpisodes=max_episodes, ...
%         MaxStepsPerEpisode=128, ...
%         StopTrainingCriteria="EpisodeCount", ...
%         StopTrainingValue=max_episodes, ...
%         SimulationStorageType= "file", ...
%         SaveAgentCriteria="EpisodeReward",...
%         SaveAgentDirectory=[base_path,'/','agents',agent_name],...
%         ScoreAveragingWindowLength=100, ...
%         UseParallel= 1, ...  
%         Verbose=false);
%         trainOpts.ParallelizationOptions.Mode = "async";
%     else
%         disp('OnPolicy, sync parrallelization')
%         trainOpts = rlTrainingOptions(...
%         MaxEpisodes=max_episodes, ...
%         MaxStepsPerEpisode=128, ...
%         StopTrainingCriteria="EpisodeCount", ...
%         StopTrainingValue=max_episodes, ...
%         SimulationStorageType= "file", ...
%         SaveAgentCriteria="EpisodeReward",...
%         SaveAgentDirectory=[base_path,'/','agents',agent_name],...        
%         ScoreAveragingWindowLength=100, ...
%         UseParallel= 1, ...  
%         Verbose=false);
%         trainOpts.ParallelizationOptions.Mode = "sync";        
%     end
%     training_stats = train(agent, env, trainOpts);
%     results = collectTrainingResults(env, agent, agent_name);
%     results.training_stats = training_stats;
% end
function results = trainStandardAgent(agent, env, agent_name, max_episodes, base_path)
    % Create directory for saving agents
    agent_dir = [base_path, '/', 'agents', agent_name];
    mkdir(agent_dir);
    
    % Determine if agent is off-policy
    offPolicyAgents = ["rlDDPGAgent", "rlTD3Agent", "rlSACAgent"];
    isOffPolicy = any(strcmp(class(agent), offPolicyAgents));
    
    % Set up training options with multiple save points :cite[1]:cite[8]
    % Save at every 10% of training, for example
    save_points = unique(round(linspace(1, max_episodes, 10)));
    
    if isOffPolicy || strcmp(agent_name, 'A3C')
        disp('OffPolicy, async parallelization')
        trainOpts = rlTrainingOptions(...
            MaxEpisodes = max_episodes, ...
            MaxStepsPerEpisode = 128, ...
            StopTrainingCriteria = "EpisodeCount", ...
            StopTrainingValue = max_episodes, ...
            SimulationStorageType = "file", ...
            SaveAgentCriteria= 'Custom', ...
            SaveAgentValue= @myCustomSaveFunction, ... % Use function handle
            SaveAgentDirectory=agent_dir,...
            ScoreAveragingWindowLength = 100, ...
            UseParallel = true, ...
            Verbose = false);
        trainOpts.ParallelizationOptions.Mode = "async";
    else
        disp('OnPolicy, sync parallelization')
        trainOpts = rlTrainingOptions(...
            MaxEpisodes = max_episodes, ...
            MaxStepsPerEpisode = 128, ...
            StopTrainingCriteria = "EpisodeCount", ...
            StopTrainingValue = max_episodes, ...
            SimulationStorageType = "file", ...
            SaveAgentCriteria= 'Custom', ...
            SaveAgentValue= @myCustomSaveFunction, ... % Use function handle
            SaveAgentDirectory=agent_dir,...
            ScoreAveragingWindowLength = 100, ...
            UseParallel = true, ...
            Verbose = false);
        trainOpts.ParallelizationOptions.Mode = "sync";
    end
    
    training_stats = train(agent, env, trainOpts);
    results = collectTrainingResults(env, agent, agent_name);
    results.training_stats = training_stats;
end
function shouldSave = myCustomSaveFunction(trainingStats)
    % Save if the episode reward exceeds a threshold
    currentReward = trainingStats.EpisodeReward(end);
    shouldSave = (currentReward > -inf); % Returns true or false
end